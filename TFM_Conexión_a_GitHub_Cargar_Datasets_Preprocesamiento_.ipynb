{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Conexión a GitHub"
      ],
      "metadata": {
        "id": "MIMPq3EWpWeZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjGyP64nlbGn",
        "outputId": "e129a8d2-54c4-440b-f833-227b4f16f0ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Montar Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar Git\n",
        "!apt-get install git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxGpboveloNO",
        "outputId": "354af370-2ade-439c-c0c3-38017138980f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.11).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso necesario luego de haber ya clonado 1 vez el repositorio para que no genere error\n",
        "# Eliminar el repositorio clonado previamente\n",
        "#!rm -rf tfm-pln-es"
      ],
      "metadata": {
        "id": "cGFmb_ghXtC8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Previamente ha sido necesario crear un repositorio en GitHub"
      ],
      "metadata": {
        "id": "9p3caEukYZva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clonar el repositorio privado usando token de acceso\n",
        "!git clone https://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@github.com/alttal/tfm-pln-es.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4BPfUeKlun5",
        "outputId": "32852a31-d69f-4f3f-a59e-daa167c729a4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tfm-pln-es'...\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 15 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (15/15), 243.20 KiB | 1.30 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carga de datasets"
      ],
      "metadata": {
        "id": "yfzvHKcOpejw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Previamente ha sido necesario cargar los dos conjuntos de datos al repositorio creado en GitHub"
      ],
      "metadata": {
        "id": "d2hUc4CDYPfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Leer dataset de comentarios de España\n",
        "df_es = pd.read_csv('tfm-pln-es/ES-data-v1.txt', delimiter=';')\n",
        "# Vista de las primeras instancias\n",
        "print(df_es.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj5D6fQ1mC8E",
        "outputId": "0415bdc1-0655-4c82-e8e7-d3f051ee849f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id label                                               text\n",
            "0   1   POS                                            Genial \n",
            "1   2   POS  Es ideal para ir de chico malote. Yo como no m...\n",
            "2   3   POS                                 A mí hijo le gusta\n",
            "3   4   NEG  Producto asiático que para nada es la talla qu...\n",
            "4   5   NEG                             La empresa no es sería\n",
            "5   6   POS  Chubasquero ligero, perfecto para entretiempo....\n",
            "6   7   POS  Perfecta, aunque talla poco, elegir una talla ...\n",
            "7   8   POS  Buena calidad y muy suave al tacto, de al pego...\n",
            "8   9   POS  Mido 1,80 y peso 80 kg., la talla L me queda p...\n",
            "9  10   POS  El material tiene buena pinta y queda bastante...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Leer dataset de comentarios de Argentina\n",
        "df_ar = pd.read_csv('tfm-pln-es/AR-data-v1.txt', delimiter=';')\n",
        "# Vista de las primeras instancias\n",
        "print(df_ar.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qa0xDUTBpimU",
        "outputId": "1479c980-e140-4cdd-e249-6b3fef209842"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id label                                               text\n",
            "0   1   POS  La pollera pantalón es de excelente calidad y ...\n",
            "1   2   POS  Compren sin dudas chicas! no solo q es muy fac...\n",
            "2   3   POS                                       Es divino!!.\n",
            "3   4   POS                                  Me encantó 10/10.\n",
            "4   5   POS  La más linda y cómoda ! le voy a dar mucho uso...\n",
            "5   6   POS  La pollera talle 1 es ideal para una adolescen...\n",
            "6   7   POS               Linda prenda me quedo como esperaba.\n",
            "7   8   POS        Me encantó!!!! todo super como lo esperaba!\n",
            "8   9   POS                                         Muy lindo.\n",
            "9  10   POS             Le encanto a mi hija buena confección.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocesamiento"
      ],
      "metadata": {
        "id": "PvwnvnsEY8b3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funciones creadas para el preprocesamiento"
      ],
      "metadata": {
        "id": "G1TrYSPeYk99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Se importa módulo de expresiones regulares\n",
        "#Información: https://docs.python.org/3/library/re.html#regular-expression-objects\n",
        "import re\n",
        "\n",
        "#Transformación del texto a minúsculas\n",
        "def covert_min(texto):\n",
        "  if isinstance(texto, str):\n",
        "    return texto.lower()\n",
        "  return texto\n",
        "\n",
        "#Eliminación de tildes\n",
        "def delete_acc(texto):\n",
        "  if isinstance(texto, str):\n",
        "    texto = re.sub(r\"[àáâãäå]\", \"a\", texto)\n",
        "    texto = re.sub(r\"[èéêë]\", \"e\", texto)\n",
        "    texto = re.sub(r\"[ìíîï]\", \"i\", texto)\n",
        "    texto = re.sub(r\"[òóôõö]\", \"o\", texto)\n",
        "    texto = re.sub(r\"[ùúû]\", \"u\", texto)\n",
        "    return texto\n",
        "  return texto\n",
        "\n",
        "#Eliminación de algunos signos de puntuación + caracteres especiales\n",
        "import string\n",
        "def delete_punctuation(texto):\n",
        "  if isinstance(texto, str):\n",
        "    punctuation_signs = string.punctuation.replace('!', '').replace('¡', '').replace('?', '').replace('¿', '').replace('$', '').replace('€', '')\n",
        "    translator = str.maketrans('', '', punctuation_signs)\n",
        "    return texto.translate(translator)\n",
        "  return texto\n",
        "\n",
        "#Eliminar palabras con menos de 2 letras\n",
        "def delete_less_2(texto):\n",
        "  if isinstance(texto, str):\n",
        "    palabras = texto.split()\n",
        "    palabras_mas_2 = [palabra for palabra in palabras if len(palabra) >= 2]\n",
        "    return ' '.join(palabras_mas_2)\n",
        "  return texto\n",
        "\n",
        "#Reducción de caracteres repetidos\n",
        "def reduce_letters_3(texto):\n",
        "  if isinstance(texto, str):\n",
        "    pattern = r'\\b\\w*(?:(\\w)\\1{2,})\\w*\\b'\n",
        "    return re.sub(pattern, ' ', texto)\n",
        "  return texto\n",
        "\n",
        "#Estandarización de expresiones de risa\n",
        "def standard_risa(texto):\n",
        "  if isinstance(texto, str):\n",
        "    pattern = r'\\b(?:a*ha*ha*|a*ja*ja*)+\\b'\n",
        "    return re.sub(pattern, 'jaja', texto)\n",
        "  return texto\n",
        "\n",
        "def preprocesamiento(texto):\n",
        "  texto = covert_min(texto)\n",
        "  texto = delete_acc(texto)\n",
        "  texto = delete_punctuation(texto)\n",
        "  texto = delete_less_2(texto)\n",
        "  texto = reduce_letters_3(texto)\n",
        "  texto = standard_risa(texto)\n",
        "  return texto"
      ],
      "metadata": {
        "id": "VyTpm8ThoFSi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplicación del preprocesamiento"
      ],
      "metadata": {
        "id": "4Ahz1tbtYqMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se aplican todos los pasos de preprocesamiento a los datasets\n",
        "df_es['text'] = df_es['text'].apply(preprocesamiento)\n",
        "df_ar['text'] = df_ar['text'].apply(preprocesamiento)"
      ],
      "metadata": {
        "id": "jp0uFI_OoM9r"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Vemos la cantidad de instancias de cada dataset original\n",
        "print(\"Estructura dataset España\")\n",
        "print(df_es.shape)\n",
        "print(\"Estructura dataset Argentina\")\n",
        "print(df_ar.shape)"
      ],
      "metadata": {
        "id": "HZQNgaWJolF1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d65eb10c-505a-44aa-ab85-cc7fee5ad76a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estructura dataset España\n",
            "(3125, 3)\n",
            "Estructura dataset Argentina\n",
            "(3125, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Eliminación de duplicados exactos en ambos datasets\n",
        "df_es_proc = df_es.drop_duplicates(subset=['text'])\n",
        "df_ar_proc = df_ar.drop_duplicates(subset=['text'])"
      ],
      "metadata": {
        "id": "Y9Ra06DJoo8G"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Eliminación de columna \"id\" en ambos datasets\n",
        "df_es = df_es_proc.drop(columns=['id'])\n",
        "df_ar = df_ar_proc.drop(columns=['id'])"
      ],
      "metadata": {
        "id": "-7G8iQiQow3R"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Vemos la cantidad de instancias y columnas de los datasets tras el preprocesamiento\n",
        "print(\"Estructura dataset España\")\n",
        "print(df_es.shape)\n",
        "print(\"Estructura dataset Argentina\")\n",
        "print(df_ar.shape)"
      ],
      "metadata": {
        "id": "uJxTyLKWpO_K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "544766f2-74e3-4af8-efa1-d6e6ef5b4caa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estructura dataset España\n",
            "(3036, 2)\n",
            "Estructura dataset Argentina\n",
            "(2903, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Vemos ejemplos para ambos datasets luego del preprocesamiento\n",
        "#España\n",
        "# Vista de las primeras instancias\n",
        "print(df_es.head(10))\n",
        "#Argentina\n",
        "# Vista de las primeras instancias\n",
        "print(df_ar.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpRsUhIkZfSo",
        "outputId": "cbad61c2-c85a-4f9d-861e-8a959d4038b5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  label                                               text\n",
            "0   POS                                             genial\n",
            "1   POS  es ideal para ir de chico malote yo como no me...\n",
            "2   POS                                   mi hijo le gusta\n",
            "3   NEG  producto asiatico que para nada es la talla qu...\n",
            "4   NEG                             la empresa no es seria\n",
            "5   POS  chubasquero ligero perfecto para entretiempo e...\n",
            "6   POS  perfecta aunque talla poco elegir una talla ma...\n",
            "7   POS  buena calidad muy suave al tacto de al pego pa...\n",
            "8   POS     mido 180 peso 80 kg la talla me queda perfecta\n",
            "9   POS  el material tiene buena pinta queda bastante bien\n",
            "  label                                               text\n",
            "0   POS  la pollera pantalon es de excelente calidad of...\n",
            "1   POS  compren sin dudas chicas! no solo es muy fache...\n",
            "2   POS                                        es divino!!\n",
            "3   POS                                    me encanto 1010\n",
            "4   POS  la mas linda comoda le voy dar mucho uso soy u...\n",
            "5   POS  la pollera talle es ideal para una adolescente...\n",
            "6   POS                linda prenda me quedo como esperaba\n",
            "7   POS        me encanto!!!! todo super como lo esperaba!\n",
            "8   POS                                          muy lindo\n",
            "9   POS                le encanto mi hija buena confeccion\n"
          ]
        }
      ]
    }
  ]
}